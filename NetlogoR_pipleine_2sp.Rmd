---
title: "Netlogo to R Pipeline: Resource Competition"
author: "Shannon Carter"
date: "March 11, 2019"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: united
    highlight: tango 
---

# Goal

The objective here is to make a clean reproducible pipeline to transform Netlogo output into a tidy rectangular dataframe. Here, I import behavior space data (i.e., experiment results) from Netlogo to R. The data I've imported here does several 'runs' (multiple treatments and replicates) of an simulation testing effects of phenology on consumer-resource interactions. There is summary data for each run (i.e., number of survivors, amount of time) and there's also time series info on size for each turtle/agent. Here, I process the data and make some diagnostic plots to finetune the model.

```{r setup, include = F}
knitr::opts_chunk$set(echo = T, warning = F, message = F)

## Set working directory and clear memory
setwd("C:\\Users\\Shannon\\Desktop\\GitHub Repos\\phenology-abm")
rm(list = ls(all = T))

## Load required packages
library(tidyverse)
library(reshape2)
library(RColorBrewer)
library(lme4)
library(wesanderson)
library(ggsci)
library(extrafont)
#extrafont::loadfonts(device = "win")


## Load universal plotting elements
mytheme <- theme_light(base_size = 15, base_family = "Poppins") +
  theme(legend.text = element_text(size = 10),
        legend.title = element_text(size = 11),
        text = element_text(size = 14, family = "Rockwell"),    
        axis.title = element_text(size = 12),
        panel.grid = element_blank())

```
# Load Final Data

When revisiting the same behavior space multiple times, skip the data processing and just load the final tidy data. Every time I do a new behavior space in NetLogo, I'll run the processing steps below and these data frames will be updated.

```{r load data}

# Processing to creat these dfs is done below, but can load these if working w same BS
ind_time <- read.csv("individual_time2sp.csv", header = T)
ind <- read.csv("ind.csv", header = T)
run <- read.csv("run.csv", header = T)
trt <- read.csv("trt.csv", header = T)

# Get factors in line
ind_time$asym_fish <- factor(ind_time$asym_fish, levels = c("none", "mild", "strong"))
ind_time$sync_fish <- factor(ind_time$sync_fish, levels = c("low", "med", "high"))

ind$asym_fish <- factor(ind$asym_fish, levels = c("none", "mild", "strong"))
ind$sync_fish <- factor(ind$sync_fish, levels = c("low", "med", "high"))

run$asym_fish <- factor(run$asym_fish, levels = c("none", "mild", "strong"))
run$sync_fish <- factor(run$sync_fish, levels = c("low", "med", "high"))

trt$asym_fish <- factor(trt$asym_fish, levels = c("none", "mild", "strong"))
trt$sync_fish <- factor(trt$sync_fish, levels = c("low", "med", "high"))

```

# Import Raw Data 

First, be sure you export behavior space data from Netlogo in "table" format. When the raw data is exported as a spreadsheet, it comes in a really gnarly format. I haven't figured out a way for R to read it because it's not even close to rectangular, big header, mix of space delimited and bracket delimited, etc.. It's a mess. The table is still a bit messy, but much easier to wrangle.

First, load the data. I've done a ton of different experiments in NetLogo, and not always certain each new one will be an improvement over the old or even work at all. So I keep most of the runs and number the files sequentially.

```{r load table data}

data <- read.table("ABM_2Consumer_2.csv",
                   header = T,  
                   sep = ',',        # define the separator between columns
                   skip = 6,         # 6 header rows we don't need
                   quote = "\"",     # correct the column separator
                   fill = T)         # add blank fields if rows have unequal length
```

# Inspect Data

First, let's rename columns and drop some that we don't need. I keep some columns that are the same across all model runs because it will be useful to call them later, especially since different runs of the experiment might have differetn values. Some columns will always be the same, or are irrelevant. These I drop. 

For this model, I had two turtle types (fishes and dflies), and varied the timing of hatching and densities of each. Outputs I collected from Netlogo were number of survivors of each turtle type and a vector of sizes for each individual turtle.

```{r inspect}
# select and rename columns. new_name = old name. 
# renaming everything I keep, so can rename with select
test <- data %>% 
  select(run_num = X.run.number.,                  # each run number is an experimental unit
         n_fish = n.fishes,                        # two types of "turtles" here: fish & dfly
         n_dfly = n.dflies,                        # n_fish/dfly is the initial number
         mean_fish = mean.hatch.fishes,            # mean hatching timing of fish
         mean_dfly = mean.hatch.dflies,            # mean hatching timing of dflies
         sync_fish = var.hatch.fishes,             # amount of variation in ind hatching timing
         sync_dfly = var.hatch.dflies,             # standard deviation of normal distribution
         asym_fish = asym.slope.fishes,            # size-dependent per capita effects 
         asym_dfly = asym.slope.dflies,            # 0-1; 0 = all ind same, 1 = eat prop to body size
         surv_fish = n.meta.fishes,                # number that 'metamorphed,' i.e., survived to next stage
         surv_dfly = n.meta.dflies,                # size and time of metam based on dynamic growth rate
         surv_tot  = n.meta.total,                 # surv_fish + surv_dfly
         biom_fish = biom.fishes,                  # sum size of all metamorphed individuals
         biom_dfly = biom.dflies,                  # sum size of all metamorphed individuals
         biom_tot  = biom.total,                   # biom_fish + biom_dfly
         meta_fish = X.meta.fish...of.fishes,      # vector of survival outcome for each individual
         meta_dfly = X.meta.dfly...of.dflies,      # i.e., [0 0 1 1 0 1 1 ...] each # = 1 individual
         sizes_fish = X.size.list.fish..of.fishes, # list of size for each ind for each time step
         sizes_dfly = X.size.list.dfly..of.dflies) # i.e., [0 0 1 ... 9 9 9] [0 0 1 ... 6 7 7] [1 ind]
          
# Extract parameter values-- these are the 'treatments', inputs, and run-level results of the model for each run
# I'll rejoin the output data with params later, after some summarizing/processing
# Here, add qualitative levels for the treatment parameters. This will be different for each BS
params <- test[,1:15]
params$sync_fish <- as.factor(params$sync_fish)
params$asym_fish <- as.factor(params$asym_fish)
levels(params$sync_fish) <- c("high", "med", "low")
levels(params$asym_fish) <- c("none", "mild", "strong")

params$sync_dfly <- as.factor(params$sync_dfly)
params$asym_dfly <- as.factor(params$asym_dfly)
levels(params$sync_dfly) <- c("high", "med", "low")
levels(params$asym_dfly) <- c("none", "mild", "strong")

```

# Parse Individuals

The 'sizes_x' columns have a time series of size for each individual. So in this case, each 'sizes_x' column contains 40 individuals x 250 time steps values. Individuals are contained in brackets, with space-delimited values representing the individual's size at that time step, i.e., [0 0 0 1 2 ... 9] [0 0 1 1 ... 5]. We ultimately want one row per individual per time step. So first, we need to separate by "]" to put individuals in columns, then gather individuals to rows. Then separate rows by " " to put time step in columns, then gather time to rows. All the while, doing fishes and dflies in parallel to maintain species identity.

I treat the 'meta_x' columns in this step too. They're formatted similarly, except there's no time series- just one value per individual, i.e., [0 0 1 1 0 1 0 ...]. So I only have to separate and gather once.

```{r parse individuals}

# First, separate meta and sizes columns. Now each column only has data for one individual
test <- test %>% 
  separate(meta_fish,                               # separate meta_fish 
          into = paste("m.f_", c(1:40), sep = ""),  # labels for new vars: mf_1, mf_2... m = meta, f = fish
          sep = " ") %>%                            # every space marks a new ind
  separate(meta_dfly,
          into = paste("m.d_", c(1:40), sep = ""),
          sep = " ") %>% 
  separate(sizes_fish,                              # separate sizes_fish
           into = paste("s.f_", c(1:40), sep = ""), # labels for new vars: sf_1, sf_2... s = size, f = fish
           sep = "]") %>%                           # every ] marks a new ind
  separate(sizes_dfly,                              
           into = paste("s.d_", c(1:40), sep = ""),  
           sep = "]")                               

# This megapipe spreads and gathers across meta and size for both species
# It's hard to follow all together- was built piece by piece to troubleshoot, and put together at the end
test <- test %>%
  select(run_num, m.f_1:m.f_40, m.d_1:m.d_40, s.f_1:s.f_40, s.d_1:s.d_40) %>% # keep run_num as unique id
  gather(key, value, -run_num) %>%                                            # gather all but run_num
  separate(key, into = c("var_sp", "id"), sep = "_") %>%  # 'var_sp' indicates 'variable' or 'species'
  spread(var_sp, value) %>%                               # spread by 'var_sp' placeholder var
  gather(key, value, -run_num, -id) %>% 
  separate(key, into = c("var", "sp")) %>% 
  spread(var, value) %>% 
  arrange(run_num, as.numeric(id), sp)

# Remove the brackets
test$m <- gsub("[", "", test$m, fixed = T)
test$s <- gsub("[", "", test$s, fixed = T)
test$m <- gsub("]", "", test$m, fixed = T)
test$s <- gsub("]", "", test$s, fixed = T)

```

# Parse Time Series

Now, do the same separate and gather operations to parse the time vector and put in long format.

```{r parse time}

# Separate the size time series- each space represents a new time point
ind_time <- test %>% 
  separate(s, into = as.character(c(0:250)), sep = " ") %>% # it's easiest for each run to be the same length
  select(-c(as.character(0))) %>%                           # I drop this because there's only a value for ind 1
  group_by(run_num) %>% 
  gather(as.character(1:250), key = "time", value = 'size') %>%
  rename(meta = m) %>% 
  arrange(run_num, sp, as.numeric(id))

# Netlogo is bad at rounding, so have to do it here
ind_time$size <- round(as.numeric(ind_time$size), 3)
ind_time$time <- as.numeric(ind_time$time)

# Rejoin with data associated with each run number (trt info, run-level response vars)
ind_time <- left_join(ind_time, params, by = "run_num")
ind_time <- ind_time %>%
  select(run_num, sync_fish, sync_dfly, asym_fish, asym_dfly,  # trt info
         surv_fish, surv_dfly, biom_fish, biom_dfly, biom_tot, # run-level output
         time, sp, id, meta, size)                             # ind/time output

write.csv(ind_time, "individual_time2sp.csv")

```

# Summarize by Individual

Now, I want to make some summarised datasets. First with one row per individual, then with one row per run number, and finally with one row per treatment. 

```{r individual summary}
 
# First, summarize by individual and add some individual level properies
ind <- ind_time %>% 
  group_by(run_num, sp, id, meta) %>%
  summarise(max_size = max(size),                    # max/final size. size at metam or death
            hatch_date = min(time[size > 0]),        # hatch date = when size jumps from 0
            end_date = min(time[size == max(size)]), # end (meta or death) date is first day at max size
            growth_time = end_date - hatch_date,     # lifespan
            growth_rate = max(size)/growth_time)     # lifetime growth rate; size/lifespan

# Rejoin with parameters and write csv
ind <- left_join(ind, params, by = "run_num")
ind <- ind %>%
  select(run_num, sync_fish, sync_dfly, asym_fish, asym_dfly,  # trt info
         surv_fish, surv_dfly, biom_fish, biom_dfly, biom_tot, # run-level output
         sp, id, meta, hatch_date,       
         end_date, growth_time, growth_rate, max_size)
write.csv(ind, "ind.csv")

# This is a good way to verify that the calculations worked
# N_survivors from netlogo should = sum or metamorphs
ind$meta <- as.numeric(ind$meta)
check <- ind %>% 
  group_by(run_num, surv_dfly, surv_fish) %>%
  summarize(meta_check = sum(meta)) %>% 
  ggplot(aes(x = surv_fish + surv_dfly, y = meta_check)) +
  geom_point(alpha = 1/5) + theme_bw() +
  geom_abline(slope = 1, intercept = 0)
check
```

# Summarize by Treatment

Now, I want to summarize to get means and error for each run and each treatment. 
```{r treatment summary}

# first, by run number
run <- ind %>% 
  group_by(run_num, sp) %>%
  filter(meta == 1) %>%                              # response variables only consider survivors
  summarise(mean_biom = sum(max_size),               # check this and survival against raw output
            se_biom   = "NA",                        # 1 biom value per run, so no error
            mean_surv = sum(meta),                   # check this an biom against raw output
            se_surv   = "NA",                        # 1 surv value per run; just a placeholder
            mean_mass = mean(max_size),              # should be biom/surv
            se_mass   = sd(max_size)/sqrt(sum(meta)),# error
            mean_emer = mean(end_date),              # emer is emergence date-- phenology of emergence
            se_emer   = sd(end_date)/sqrt(sum(meta)),# error
            mean_grow = mean(growth_rate),           # grow is individual time to development. size/time
            se_grow   = sd(growth_rate)/sqrt(sum(meta))) %>% 
  gather(mean_mass, se_mass, mean_emer, se_emer,     # gather all response variables
         mean_grow, se_grow, 
         mean_biom, se_biom, mean_surv, se_surv,
         key = "variable", value = "abs_value") %>% 
  separate(variable, into = c("prop", "var"), by = "_") %>% # separate the name-- mean/se and variable
  spread(prop, abs_value) %>%                               # spread so mean and se are separate columns
  arrange(run_num, sp)

# Rejoin with parameters & write csv
run <- left_join(run, params, by = c("run_num"))
run$mean <- round(as.numeric(run$mean), 2)
run$se <- round(as.numeric(run$se), 2)
run <- run %>% select(-c(surv_fish, surv_dfly, biom_fish, biom_dfly)) # these are redundant w calcs above
write.csv(run, "run.csv")

# Now by treatment
trt <- run %>% 
  group_by(sync_fish, asym_fish, sp, var) %>% 
  summarise(mean_exp = mean(mean),            
            se_exp   = sd(mean)/sqrt(6))      # 6 replicates

# Rejoin with parameters & write csv
trt <- left_join(trt, params, by = c("sync_fish", "asym_fish"))
trt <- trt %>% 
  select(-run_num, -c(14:19)) %>% 
  unique(.) %>% 
  rename(mean = mean_exp, se = se_exp) %>%
  select(sync_fish, sync_dfly, asym_fish, asym_dfly, # put them in an intuitive order
         mean_fish, mean_dfly, n_fish, n_dfly, 
         sp, var, mean, se)

trt$mean <- round(as.numeric(trt$mean), 2)
trt$se <- round(as.numeric(trt$se), 2)
write.csv(trt, "trt.csv")

```

# Plots

Here are some diagnostic plots to get a quick look at the data. These will give an idea of what parameter space is reasonable and interesting to explore in future behavior space runs.


```{r, echo = F}
ggplot(ind, aes(x = hatch_date, color = sp, fill = sp)) + mytheme +
  geom_density(alpha = 0.5, size = 1.2) +
  facet_grid(sync_fish ~ asym_fish) +
  scale_color_manual(values = c("#F28335", "#489C92")) +
  scale_fill_manual(values = c("#F28335", "#489C92")) +
  labs(title = "Hatching timing treatments",
       x = "hatching date",
       y = "density of individuals") 
```


```{r, echo = F}
#ggplot(subset(ind, subset = (meta ==1)),
ggplot(ind, aes(x = hatch_date, y = max_size, color = sp)) + mytheme +
  geom_point(size = 1, alpha = 0.2, position = 'jitter') +
  stat_smooth() +
  facet_grid(sync_fish ~ asym_fish, scales = 'free') + 
  scale_color_manual(values = c("#F28335", "#489C92")) +
  labs(title = "Final size by hatching date",
       x = "hatching date",
       y = "final size")

```

```{r, echo = F}

# even if they beat resource by 6 days
ggplot(subset(ind, subset = (meta == 1)), 
       aes(x = hatch_date, y = growth_time, color = sp)) + mytheme +
  geom_point(alpha = 0.2, size = 1) +
  stat_smooth(method = "lm", formula = y ~ poly(x, 2), se = T, size = 1) +
  facet_grid(sync_fish ~ asym_fish, scales = "free") + 
  scale_color_manual(values = c("#F28335", "#489C92")) + 
  labs(title = "Growth rate by hatching date",
       x = "hatching date",
       y = "days to metamorphosis")

```

```{r, echo = F}
# Looks like in several cases, there are some individuals hatching on the last day, way later than the others. Check.
ggplot(ind, aes(x = hatch_date, y = meta, color = sp)) + mytheme +
  geom_point(alpha = 0.25) + 
  stat_smooth(method = 'glm', method.args = 'binomial', se = F, size = 1.5) +
  facet_grid(sync_fish ~ asym_fish, scales = "free") + 
  xlab("hatch date") + ylab("probability of survival") +
  scale_color_manual(values = c("#F28335", "#489C92")) +
  labs(title = "Survival probability by hatching date",
       x = "hatching date",
       y = "probability of survival")
```

```{r, echo = F}
ggplot(subset(trt, subset = (sp == "f")),
       aes(x = sync_fish, y = mean_exp, color = asym_fish)) + mytheme +
  geom_point(size = 2) + 
  geom_errorbar(aes(max = mean_exp + se_exp, min = mean_exp - se_exp), width = 0) +
  geom_line() +
  #stat_smooth(size = 2, method = "lm", se = T, 
  #            aes(x = sync_fish, fill = asym_fish)) +
  facet_wrap(~ var, scales = "free") +
  xlab("mean arrival") + ylab("number survivors")  +
  scale_fill_manual(values = wes_palette(n = 3, name = "GrandBudapest1")) +
  scale_color_manual(values = wes_palette(n = 3, name = "GrandBudapest1")) +
  labs(title = "Responses of vital rates to phenology manipulations",
       x = "phenological synchrony of fish",
       y = "mean +/- se")

```

```{r, echo = F}

ggplot(subset(ind, subset = (sp == "f")), 
                aes(x = hatch_date, y = meta, color = asym_fish)) +
  geom_point(alpha = 0.25) + theme_bw() +
  stat_smooth(method = 'glm', method.args = 'binomial', size = 2, alpha = 0.5, se = F) +
  facet_wrap(~ sync_fish) +
  scale_color_manual(values = wes_palette(n = 3, name = "GrandBudapest1")) +
  labs(title = "Probability of dragonfly survival by hatching date",
       x = "hatching date",
       y = "probability of survival")
```

```{r, echo = F}

## Subset to include only individuals that metamorphed
ind_surv <- subset(ind, subset = (meta == 1 & sp == "f"))

## Original hatching and metamorph
ggplot(ind_surv, aes(hatch_date)) + theme_bw() +
  # gray: original/imposed hatching synchrony
  geom_density(size = 1, alpha = 0.25, fill = "black", color = "gray39") + 
  # blue: metamorphosis dates of survivors, scaled to day 0
  geom_density(data = ind_surv, size = 1, alpha = 0.5, color = "steelblue4", fill = "steelblue4",
               aes(x = end_date)) +
  facet_grid(sync_fish ~ asym_fish , scales = "free_y") + 
  theme(strip.text.x = element_text(size = 14),
        strip.text.y = element_text(size = 14)) +
  labs(title = "Phenology across ontogeny",
       x = "date",
       y = "density of individuals")

```
