---
title: "Netlogo to R Pipeline: Consumer-Resource"
author: "Shannon Carter"
date: "March 11, 2019"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: united
    highlight: tango 
---

# Goal

The objective here is to make a clean reproducible pipeline to transform Netlogo output into a tidy rectangular dataframe. Here, I import behavior space data (i.e., experiment results) from Netlogo to R. The data I've imported here does several 'runs' (multiple treatments and replicates) of an simulation testing effects of phenology on consumer-resource interactions. There is summary data for each run (i.e., number of survivors, amount of time) and there's also time series info on size for each turtle/agent. Here, I process the data and make some diagnostic plots to finetune the model.

```{r setup, include = F}
knitr::opts_chunk$set(echo = T, warning = F, message = F)

## Set working directory and clear memory
setwd("C:\\Users\\Shannon\\Desktop\\GitHub Repos\\phenology-abm")
rm(list = ls(all = T))

## Load required packages
library(tidyverse)
library(reshape2)
library(RColorBrewer)
library(lme4)
library(wesanderson)
library(ggsci)
library(extrafont)
#extrafont::loadfonts(device = "win")


## Load universal plotting elements
mytheme <- theme_bw(base_size = 15, base_family = "Franklin Gothic Medium") +
  theme(legend.text = element_text(size = 10),
        legend.title = element_text(size = 11),
        text = element_text(size = 14),     
        axis.title = element_text(size = 12),
        axis.text  = element_text(size = 10, family = "Consolas"),
        panel.grid = element_blank())

```

# Load Final Data

When revisiting the same behavior space multiple times, skip the data processing and just load the final tidy data. Every time I do a new behavior space in NetLogo, I'll run the processing steps below and these data frames will be updated.

```{r load data, echo = F, include = F}

# Processing to creat these dfs is done below, but can load these if working w same BS
ind_time <- read.csv("ind_time1sp.csv", header = T)
ind <- read.csv("ind1sp.csv", header = T)
run <- read.csv("run1sp.csv", header = T)
trt <- read.csv("trt1sp.csv", header = T)

# Get factors in line
ind_time$asymmetry <- factor(ind_time$asymmetry, levels = c("none", "mild", "strong"))
ind_time$synchrony <- factor(ind_time$synchrony, levels = c("low", "med", "high"))

ind$asymmetry <- factor(ind$asymmetry, levels = c("none", "mild", "strong"))
ind$synchrony <- factor(ind$synchrony, levels = c("low", "med", "high"))

run$asymmetry <- factor(run$asymmetry, levels = c("none", "mild", "strong"))
run$synchrony <- factor(run$synchrony, levels = c("low", "med", "high"))

trt$asymmetry <- factor(trt$asymmetry, levels = c("none", "mild", "strong"))
trt$synchrony <- factor(trt$synchrony, levels = c("low", "med", "high"))

```

# Import Data 

First, be sure you export behavior space data from Netlogo in "table" format. When the raw data is exported as a spreadsheet, it comes in a really gnarly format. I haven't figured out a way for R to read it because it's not even close to rectangular, big header, mix of space delimited and bracket delimited, etc.. It's a mess. The table is still a bit messy, but much easier to wrangle.

First, load the data. I've done a ton of different experiments in NetLogo, and not always certain each new one will be an improvement over the old or even work at all. So I keep most of the runs and number the files sequentially.

```{r load table data}
## First, import the data
data <- read.table("bs_CRnometa_17.csv",
                   header = T,  
                   sep = ',',        # define the separator between columns
                   skip = 6,         # 6 header rows we don't need
                   quote = "\"",     # correct the column separator
                   fill = T)         # add blank fields if rows have unequal length
```

# Rename and Select Relevant Variables

Next, let's rename columns and drop some that we don't need. I keep some columns that are the same across all model runs because it will be useful to call them later, especially since different future experiments might have different values. Some columns will always be the same, or are irrelevant. These I drop. 

For this model, I have one turtle type (fishes), and varied the timing of hatching and per capita growth rates individuals. The Netlogo output includes parameter values and a vector of sizes over time for each turtle

```{r rename and select}
# renaming everything I keep, so can rename with select. new_name = old name. 
test <- data %>%                              # rename the df here bc the raw data takes a long time to load
  select(run_num = X.run.number.,             # each run number is an experimental unit (i.e, a mesocom)
         #total_time = X.step.,               # length of time the experiment ran
         density = n.fishes,                  # initial number of turtles
         sync = var.hatch.fishes,             # trt var: amount of variation in individual hatching timing
         asym = asym.slope.fishes,            # trt var: size dependent per capita growth rates
         n_surv = n.meta.fishes,              # number of individuals that 'metamorphed' that run
         n_dead = n.dead.fishes,              # number of individuals that did not metamorphose
         biomass = biom.fishes,               # sum mass of all survivors of a run
         mean_size = mean.size.fishes,        # mean size of individuals that metamorphosed
         meta_list = X.meta.fish...of.fishes, # list holding the survival outcome (0/1) for each individual
         sizes = X.size.list.fish..of.fishes) # list of size for each ind for each time
         
```

# Extract run level data

The data currently has 1 row per experiment run. Ultimately, we need to extract data in some columns so that we have one row per time step per individual. Even though this dataset isn't super wide, I have an easier time doing these manipulations without extraneous columns distracting me. So, I pull out the data that has one value per run (i.e., treatment variables and population level response variables like survival) and save it to rejoin with the data later.

```{r extract parameters}
# I'll rejoin the output data with params later, after some summarizing/processing
# Add qualitative levels for the treatment params, bc useful for plotting. This will be different for each BS
params <- test[,1:8]
params$synchrony <- as.factor(params$sync)
params$asymmetry <- as.factor(params$asym)
levels(params$synchrony) <- list("low" = 25, "med" = 15, "high" = 5)
levels(params$asymmetry) <- list("none" = 0, "mild" = 0.5, "strong" = 1)

```


# Parse Individuals

The 'sizes' columns have a time series of size for each individual (so each 'sizes_fish' column has X individuals x Y time steps values). We ultimately want one row per individual per time step. Let's first separate by individual. 

```{r parse individuals}
# First, separate so that each individual has it's own column
test <- test %>% 
  separate(sizes,                                      
           into = paste("size_", c(1:max(test$density)), sep = ""), # new name is size_1, size_2, etc.
           sep = "]") %>%                                           # every ] marks a new ind
  separate(meta_list,
           into = paste("meta_", c(1:max(test$density)), sep = ""), # new name is meta_1, meta_2, etc.
           sep = " ")

# some cells are left blank and not NA (because of "]]" ending), so fill those with NA
test[test==""] <- NA

# Next, I'll gather individuals so that they appear in rows
# For now, need to hardcode max number of fish
test <- test %>%
  select(run_num, meta_1: meta_80, size_1:size_80) %>% #, growth_1:growth_80) %>% 
  gather(key, value, -run_num) %>%  
  separate(key, into = c("ms", "fish_id"), sep = "_") %>%  # 'ms' indicates 'meta' or 'size', just a placeholder
  spread(ms, value) %>% 
  arrange(run_num, fish_id)
 
# Remove the brackets 
test$size <- gsub("[", "", test$size, fixed = T)
test$meta <- gsub("[", "", test$meta, fixed = T)
test$meta <- gsub("]", "", test$meta, fixed = T)

```

# Parse Time Series

Now, do the same separate and gather operations to parse the time vector and put in long format.

```{r parse time series}

# Separate the size time series- each space represents a new time point
test <- test %>% 
  separate(size, 
           into = paste("size_", c(0:250), sep =  ""),
           sep = " ") %>% 
  select(-c(size_0))       # I drop this because there's only a value for ind 1

# round all size values since NetLogo is insane
test[,-c(1:3)] <- round(as.numeric(unlist(test[,-c(1:3)])), 3)

# Gather to long format, so we now have one line per fish per time step
test <- test %>%
  #select(run_num, total_time, size_1:size_80, growth_1:growth_80) %>% 
  gather(key, value, -run_num, -fish_id, -meta) %>%  
  separate(key, into = c("size", "time"), sep = "_") %>% 
  spread(size, value) %>% 
  mutate(time = as.numeric(time),
         fish_id = as.numeric(fish_id), 
         size = as.numeric(size),
         meta = as.numeric(meta)) %>% 
  arrange(run_num, fish_id, time)

```

# Compile & Tidy

Now, rejoin with the treatment information, and write a csv. This csv has one line per individual per time step. So nrow should be max(run_num) x (ndfly + nfish) x total_time
```{r individual time}

# Rejoin with treatment identifiers for each run number
test <- left_join(test, params, by = "run_num")
ind_time <- test %>%
  select(run_num, density, sync, asym, synchrony, asymmetry,
         time, n_surv, n_dead, biomass, mean_size, fish_id, meta, size) %>% 
  rename(id = fish_id)
ind_time$size <- as.numeric(ind_time$size)

```


# Summarize by Individual

Now, I want to make some summarised datasets. First with one row per individual, then with one row per run number 

```{r individual summary}

#ind_time <- read.csv("individual_time_CR.csv", header = T)
ind_time$synchrony <- ordered(ind_time$synchrony, levels = c("low", "med", "high"))
ind_time$asymmetry <- ordered(ind_time$asymmetry, levels = c("none", "mild", "strong"))
ind_time$size <- as.numeric(ind_time$size)

#write.csv(ind_time, "ind_time1sp.csv")

# Here, set a minimum threshold for metamorphosis. Future runs will have this modeled implicitly
ind <- ind_time %>% 
  group_by(run_num, id, sync, asym, synchrony, asymmetry, n_surv, n_dead, biomass, mean_size, meta) %>%
  summarise(final_size = max(size),
            hatch_date = min(time[size > 0]),
            end_date = min(time[size == max(size)]),
            growth_time = end_date - hatch_date,
            growth_rate = max(size)/growth_time) 
#write.csv(ind, "ind1sp.csv")

```

## Summarize by Treatment 

```{r treatment summary}
# first, by run number
run <- ind %>% 
  group_by(run_num) %>%
  filter(meta == 1) %>%                              # response variables only consider survivors
  summarise(mean_biom = sum(final_size),               # check this and survival against raw output
            se_biom   = "NA",                        # 1 biom value per run, so no error
            mean_surv = sum(meta),                   # check this an biom against raw output
            se_surv   = "NA",                        # 1 surv value per run; just a placeholder
            mean_mass = mean(final_size),              # should be biom/surv
            se_mass   = sd(final_size)/sqrt(sum(meta)),# error
            mean_emer = mean(end_date),              # emer is emergence date-- phenology of emergence
            se_emer   = sd(end_date)/sqrt(sum(meta)),# error
            mean_grow = mean(growth_rate),           # grow is individual time to development. size/time
            se_grow   = sd(growth_rate)/sqrt(sum(meta))) %>% 
  gather(mean_mass, se_mass, mean_emer, se_emer,     # gather all response variables
         mean_grow, se_grow, 
         mean_biom, se_biom, mean_surv, se_surv,
         key = "variable", value = "abs_value") %>% 
  separate(variable, into = c("prop", "var"), by = "_") %>% # separate the name-- mean/se and variable
  spread(prop, abs_value) %>%                               # spread so mean and se are separate columns
  arrange(run_num)

# Rejoin with parameters & write csv
run <- left_join(run, params, by = c("run_num"))
run$abs_value <- round(as.numeric(run$mean), 2)
run$se <- round(as.numeric(run$se), 2)
run <- run %>% 
  select(run_num, synchrony, asymmetry, var, abs_value, se) #drop ones that are redundant w calcs above

# now by treatment
trt <- run %>% 
  group_by(synchrony, asymmetry, var) %>% 
  summarise(abs_value_exp = mean(abs_value),
            se_exp    = sd(abs_value)/sqrt(6))

baseline_means <- trt %>% 
  subset(synchrony == 'med' & asymmetry == 'none') 
baseline_means <- baseline_means[,3:5] 
colnames(baseline_means)[2] <- "baseline_value"

# now, add in baseline averages (conditions at med sync and symmetic comp) to run data
run <- left_join(run, baseline_means, by = "var")  
trt <- left_join(trt, baseline_means, by = "var")
   
run <- run %>% 
  mutate(baseline_adj = (abs_value - baseline_value)/baseline_value)

trt <- trt %>% 
  mutate(baseline_adj = (abs_value_exp - baseline_value)/baseline_value)
#write.csv(trt, "trt1sp.csv")
#write.csv(run, "run1sp.csv")

```

# Plots

Here are some diagnostic plots to get a quick look at the data. These will give an idea of what parameter space is reasonable and interesting to explore in future behavior space runs.

```{r}
## LOLIPOP PLOT

trt_nobaseline <- subset(trt, subset = asymmetry != "none" & synchrony != "med")
run_nobaseline <- subset(run, subset = asymmetry != "none" & synchrony != "med")

ggplot(trt_nobaseline, 
       aes(x = var, y = baseline_adj, 
           colour = interaction(asymmetry, synchrony), shape = interaction(asymmetry, synchrony)))+
  geom_point(data = run_nobaseline,
              aes(x = var, y = baseline_adj, 
                  group = interaction(asymmetry, synchrony)),
              size = 2, alpha = 0.25,
              position = position_jitterdodge(dodge.width = 0.5, jitter.width = 0.2)) +
  geom_linerange(aes(ymin = 0, ymax = baseline_adj),
              size = 1, 
              position = position_dodge(width = 0.5),
              show.legend = F) +
  geom_hline(aes(yintercept = 0), color = "grey70", size = 0.6) +
  geom_point(aes(var, baseline_adj), 
             size = 4, 
             position = position_dodge(width = 0.5)) +
  coord_flip() +
  #scale_y_continuous(limits = c(-0.5, 0.5), expand = c(0.005, 0.005)) +
  scale_shape_manual(name = "Synchrony & Symmetry",
                     labels = c("low synchrony, mild asymmetry", "low synchrony, strong asymmetry", 
                                "high synchrony, mild asymmetry", "high synchrony, strong asymmetry"),
                     values = c(19, 17, 19, 17)) +
  scale_color_manual(name = "Synchrony & Symmetry",
                     labels = c("low synchrony, mild asymmetry", "low synchrony, strong asymmetry", 
                                "high synchrony, mild asymmetry", "high synchrony, strong asymmetry"),
                     values = c("#D8B709", "#D8B709", "#02401B", "#02401B")) +
  labs(x = NULL, y = "Proportional deviation from baseline case\n(medium synchrony, symmetric competition)") +
  scale_x_discrete(breaks = c("surv", "mass", "biom", "emer", "grow"),
                   labels = c("survival", "mean per\ncapita size", "biomass export", "time to\nemergence", "mean per\ncapita growth rate")) +
  mytheme + theme(axis.text.y = element_text(family = "Franklin Gothic Medium"))
  
```

More traditional means plot
```{r}

variable_names <- list(
  'biom' = "biomass export",
  'emer' = "emergence date", 
  'grow' = "per capita growth rate", 
  'mass' = "per capita mass", 
  'surv' = "survival"
)

variable_labeller <- function(variable, value){
  return(variable_names[value])
}

ggplot(trt, aes(x = synchrony, y = abs_value_exp, 
                fill = asymmetry, color = asymmetry, group = asymmetry, shape = asymmetry)) + 
  mytheme +
  geom_line() +
  geom_point(size = 3, color = "black") +
  geom_errorbar(aes(ymin = (abs_value_exp - se_exp.x), ymax = abs_value_exp + se_exp.x), width = 0) +
  facet_wrap(~var, scales = "free", labeller = variable_labeller) +
  labs(title = "Responses of population vital rates to phenological manipulations",
       y = "mean +/- se", 
       x = "phenological synchrony at hatching") + 
  scale_color_manual(values = c("#acbab3",  "#fbd364", "#446353")) +
  scale_fill_manual(values = c("#acbab3",  "#fbd364", "#446353")) +
  scale_shape_manual(values = c(21, 24, 23))  + 
  theme(legend.position = c(0.75, 0.25)) 
  
```


Now, distributions of sizes of individuals at the end of the experiment, grouped by treatment. The vertical lines represent different size thresholds I considered for metamorphosis. Since these distributions of sizes for each treatment are so different, it doesn't make sense to set a size threshold for survival. Results are pretty sensitive to it. Instead, model optimal timing of metamorphosis so that both size and age at metamorphosis are plastic and can be captured.

```{r, echo = F}
ggplot(ind, aes(x = final_size, fill = as.factor(meta))) + mytheme +
  geom_density(alpha = 0.5, size = 0.8) +
  facet_grid(asymmetry ~ synchrony) +
  scale_fill_uchicago() +
  scale_x_continuous(limits = c(0, 15), breaks = seq(0, 15, by = 5)) +
  #geom_vline(xintercept = c(8, 10, 12), linetype = 'dashed') + 
  labs(title = "Distribution of individual body sizes by treatment",
       x = "size",
       y = "density of individuals")

ggplot(subset(ind, subset = (meta == 1)), aes(x = end_date, fill = asymmetry)) + mytheme +
  geom_vline(data = subset(trt, subset = (var == "emer")), 
             aes(xintercept = abs_value_exp, color = asymmetry), 
             linetype = 'dashed', size = 1.2) + 
  geom_density(alpha = 0.5, size = 0.8) +
  facet_grid(. ~ synchrony) +
  scale_x_continuous(limits = c(0, 250), breaks = seq(0, 250, by = 50)) +
  scale_color_manual(values = c("#acbab3",  "#fbd364", "#446353")) +
  scale_fill_manual(values = c("#acbab3",  "#fbd364", "#446353")) +
  labs(title = "Phenology at emergence",
       x = "day of emergence",
       y = "density of individuals")
```


```{r, echo = F}
growthrates <- ggplot(ind_time, 
                      aes(x = time, y = size, color = as.factor(id))) + mytheme +
  geom_point() +
  #geom_line(alpha = 0.25) +
  geom_smooth(se = F) + 
  scale_color_uchicago() +
  facet_grid(synchrony ~ asymmetry) +
  theme(legend.position = "none") 
growthrates

```


```{r, echo = F}

# size by hatch date
ggplot(ind, aes(x = hatch_date, y = final_size, color = as.factor(meta))) +
  geom_point(size = 1, alpha = 0.2, position = 'jitter') +
  stat_smooth(se = F) +
  facet_grid(asymmetry ~ synchrony) + mytheme +
  labs(title = "Final size by hatching date",
       x = "hatching date",
       y = "final size") +
  scale_color_uchicago()

# development time by hatch date
ggplot(ind, aes(x = hatch_date, y = (end_date - hatch_date), color = as.factor(meta))) +
  geom_point(size = 1, alpha = 0.2, position = 'jitter') +
  #stat_smooth(se = F) +
  facet_grid(asymmetry ~ synchrony) + mytheme +
  labs(title = "Development time by hatching date",
       x = "hatching date",
       y = "development time") +
  scale_color_uchicago()

# growth rate by hatch date
ggplot(ind, aes(x = hatch_date, y = growth_rate, color = as.factor(meta))) +
  geom_point(size = 1, alpha = 0.2, position = 'jitter') +
  stat_smooth(se = F) +
  geom_hline(yintercept = c(0.05, 0.15), linetype = 'dashed', alpha = 0.5) +
  facet_grid(asymmetry ~ synchrony) + mytheme +
  scale_x_continuous(limits = c(0, 140), breaks = seq(0, 120, by = 30)) +
  ylim(0,0.25) +
  labs(title = "Growth rate by hatching date",
       x = "hatching date",
       y = "growth rate (final size - initial size) / time") +
  scale_color_uchicago()

```

A visual of the synchrony treatments.

```{r, echo = F}
ggplot(ind, aes(x = hatch_date)) + mytheme +
  geom_density(alpha = 0.5, size = 1.2) +
  facet_grid(. ~ synchrony) +
  scale_x_continuous(limits = c(0, 140), breaks = seq(0, 120, by = 30)) +
  labs(title = "Hatching timing treatments",
       x = "hatching date",
       y = "density of individuals")
```

Probability of individuals surviving based on hatching date for each treatment

```{r, echo = F}
# Looks like in several cases, there are some individuals hatching on the last day, way later than the others. Check.
ggplot(ind, aes(x = hatch_date, y = meta, color = asymmetry)) + mytheme +
  geom_point(alpha = 0.05) + 
  stat_smooth(size = 1.5, method = 'glm', method.args = 'binomial', se = F) +
  facet_grid(synchrony ~ .) + 
  xlab("hatch date") + ylab("probability of survival") +
  theme(strip.text.x = element_text(size = 14),
        strip.text.y = element_text(size = 14)) +
  labs(title = "Survival probability by hatching date",
       x = "hatching date",
       y = "probability of survival") +
  scale_x_continuous(limits = c(0, 140), breaks = seq(0, 120, by = 30)) +
  scale_color_manual(values = c("#acbab3",  "#fbd364", "#446353")) 


```

```{r, include = F}

## Taking a look at scaling relationships in the model

#These are things pulled from the model to take a look at to examine scaling relationships between an individuals size, consumption rate, and growth rate. Some of these parameters come directly from the model formulation, and some come from data of model runs.

df <- data.frame(size = 1:10)
df$starvation <- df$size ^ 0.75
df$maxmeal <- df$size*0.8
df$growthperpatch <- rep("0.1", length(df$size))

ggplot(df, aes(x = size, y = starvation)) + theme_bw() +
  geom_point() +
  geom_line() +
  labs(y = "# patches needed to avoid starvation") +
  xlim(0, 10) #+ ylim(0, 10)

df <- data.frame(growth = seq(0, 0.9, 0.05))
df$wt5 <- 5 / (1 - df$growth)
df$wt2 <- 2 / (1 - df$growth)
df$wt8 <- 8 / (1 - df$growth)
ggplot(df, aes(x = growth, y = wt5)) + theme_bw() +
  geom_point() + 
  geom_line() +
  geom_point(aes(x = growth, y = wt2), color = 'blue') +
  geom_line(aes(x = growth, y = wt2), color = 'blue') +
  geom_point(aes(x = growth, y = wt8), color = 'green') +
  geom_line(aes(x = growth, y = wt8), color = 'green') +
  labs(y = "optimal size at metamorphosis",
       x = "growth rate")

```

